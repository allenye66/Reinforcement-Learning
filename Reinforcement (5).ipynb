{"cells":[{"metadata":{"_uuid":"e0e8d1e5-4d46-4d72-8752-c1a3e8a0b684","_cell_guid":"89979c6d-34c9-4c93-aff7-51c7115454ec","trusted":true},"cell_type":"code","source":"import gym\nimport random\nimport time\nimport numpy as np\nfrom IPython.display import clear_output\nenv = gym.make(\"FrozenLake-v0\").env\nenv.render()","execution_count":1,"outputs":[{"output_type":"stream","text":"\n\u001b[41mS\u001b[0mFFF\nFHFH\nFFFH\nHFFG\n","name":"stdout"}]},{"metadata":{"_uuid":"442562da-055e-436e-b1de-7f99a4103989","_cell_guid":"b9cb57ae-afbe-4dfd-86f4-02a823668451","trusted":true},"cell_type":"code","source":"action_space_size = env.action_space.n\nstate_space_size = env.observation_space.n\nprint(action_space_size)\nprint(state_space_size)","execution_count":2,"outputs":[{"output_type":"stream","text":"4\n16\n","name":"stdout"}]},{"metadata":{"_uuid":"20a6460b-7d88-4da6-b0ed-94b18bd33e7f","_cell_guid":"7cdcafb4-a157-43f4-a86f-c824c711104a","trusted":true},"cell_type":"code","source":"q_table = np.zeros((state_space_size, action_space_size)) #16 by 4\nprint(q_table)","execution_count":3,"outputs":[{"output_type":"stream","text":"[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]\n","name":"stdout"}]},{"metadata":{"_uuid":"3cf76671-28b5-4376-8d5f-fd34de252568","_cell_guid":"3e90ccbd-0153-4401-af1a-5e5e78bdc864","trusted":true},"cell_type":"code","source":"epochs = 100000\nmax_steps = 300\n\nlearning_rate = 0.09\ndiscount_rate = 0.99 #works best\n\nexploration_rate = 1\nmax_exploration_rate = 1\nmin_exploration_rate = 0.01\nexploration_decay_rate = 0.001","execution_count":105,"outputs":[]},{"metadata":{"_uuid":"2d439a2d-85b1-45e6-9f85-615147d1e9b5","_cell_guid":"0b683011-4450-4b3a-8679-6a9098217421","trusted":true},"cell_type":"code","source":"rewards_all = []\n\nfor episode in range(epochs):\n    state = env.reset()\n    done = False\n    current_reward = 0\n    for step in range(max_steps):\n        exploration_rate_threshold = random.uniform(0,1)\n        if exploration_rate_threshold > exploration_rate:\n            action = np.argmax(q_table[state,:])\n        else:\n            action = env.action_space.sample()\n            \n        new_state, reward, done, info = env.step(action)\n        \n        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + learning_rate*(reward  + discount_rate * np.max(q_table[new_state,:])) \n        \n        state = new_state\n        current_reward += reward\n        \n        if done == True:\n            break\n        \n    exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n    \n    rewards_all.append(current_reward)\n    \nrewards_print = np.split(np.array(rewards_all), epochs/500)\n\naccuracy = []\nfor r in rewards_print:\n    accuracy.append(sum(r/500))","execution_count":106,"outputs":[]},{"metadata":{"_uuid":"31f8c896-6e50-42fa-a962-f98d4483c9ae","_cell_guid":"66480994-956d-4819-80d2-940d2de995e3","trusted":true},"cell_type":"code","source":"count = 500\nprint(\"*******Average accuracy per 500 episodes******\\n\")\nfor i in accuracy:\n    print(count, \": \", i)\n    count += 500","execution_count":107,"outputs":[{"output_type":"stream","text":"*******Average accuracy per 500 episodes******\n\n500 :  0.03800000000000002\n1000 :  0.06200000000000004\n1500 :  0.1580000000000001\n2000 :  0.2480000000000002\n2500 :  0.3760000000000003\n3000 :  0.46800000000000036\n3500 :  0.5640000000000004\n4000 :  0.6120000000000004\n4500 :  0.6740000000000005\n5000 :  0.7040000000000005\n5500 :  0.7400000000000005\n6000 :  0.7160000000000005\n6500 :  0.7460000000000006\n7000 :  0.7340000000000005\n7500 :  0.7680000000000006\n8000 :  0.7140000000000005\n8500 :  0.7060000000000005\n9000 :  0.7340000000000005\n9500 :  0.7660000000000006\n10000 :  0.7400000000000005\n10500 :  0.7500000000000006\n11000 :  0.7420000000000005\n11500 :  0.7940000000000006\n12000 :  0.7560000000000006\n12500 :  0.7520000000000006\n13000 :  0.7700000000000006\n13500 :  0.7900000000000006\n14000 :  0.7560000000000006\n14500 :  0.7820000000000006\n15000 :  0.7260000000000005\n15500 :  0.7720000000000006\n16000 :  0.7680000000000006\n16500 :  0.7440000000000005\n17000 :  0.7140000000000005\n17500 :  0.7480000000000006\n18000 :  0.7400000000000005\n18500 :  0.7540000000000006\n19000 :  0.7320000000000005\n19500 :  0.7800000000000006\n20000 :  0.7100000000000005\n20500 :  0.6980000000000005\n21000 :  0.7660000000000006\n21500 :  0.7600000000000006\n22000 :  0.7420000000000005\n22500 :  0.7600000000000006\n23000 :  0.7580000000000006\n23500 :  0.7980000000000006\n24000 :  0.7400000000000005\n24500 :  0.7400000000000005\n25000 :  0.7620000000000006\n25500 :  0.7960000000000006\n26000 :  0.7160000000000005\n26500 :  0.7400000000000005\n27000 :  0.7420000000000005\n27500 :  0.7840000000000006\n28000 :  0.7480000000000006\n28500 :  0.7360000000000005\n29000 :  0.7460000000000006\n29500 :  0.7680000000000006\n30000 :  0.7540000000000006\n30500 :  0.7940000000000006\n31000 :  0.7620000000000006\n31500 :  0.7440000000000005\n32000 :  0.7880000000000006\n32500 :  0.7700000000000006\n33000 :  0.7640000000000006\n33500 :  0.7200000000000005\n34000 :  0.7320000000000005\n34500 :  0.7440000000000005\n35000 :  0.7340000000000005\n35500 :  0.7720000000000006\n36000 :  0.7640000000000006\n36500 :  0.7360000000000005\n37000 :  0.7340000000000005\n37500 :  0.7480000000000006\n38000 :  0.7620000000000006\n38500 :  0.7440000000000005\n39000 :  0.7640000000000006\n39500 :  0.7600000000000006\n40000 :  0.7320000000000005\n40500 :  0.7660000000000006\n41000 :  0.7260000000000005\n41500 :  0.7540000000000006\n42000 :  0.7520000000000006\n42500 :  0.7640000000000006\n43000 :  0.7500000000000006\n43500 :  0.7520000000000006\n44000 :  0.7700000000000006\n44500 :  0.7400000000000005\n45000 :  0.7400000000000005\n45500 :  0.7280000000000005\n46000 :  0.7700000000000006\n46500 :  0.7440000000000005\n47000 :  0.7460000000000006\n47500 :  0.7700000000000006\n48000 :  0.7860000000000006\n48500 :  0.7380000000000005\n49000 :  0.7080000000000005\n49500 :  0.7140000000000005\n50000 :  0.7740000000000006\n50500 :  0.7200000000000005\n51000 :  0.8140000000000006\n51500 :  0.7820000000000006\n52000 :  0.7220000000000005\n52500 :  0.7800000000000006\n53000 :  0.7540000000000006\n53500 :  0.7280000000000005\n54000 :  0.7440000000000005\n54500 :  0.8040000000000006\n55000 :  0.7360000000000005\n55500 :  0.8020000000000006\n56000 :  0.7280000000000005\n56500 :  0.7320000000000005\n57000 :  0.7660000000000006\n57500 :  0.7320000000000005\n58000 :  0.7440000000000005\n58500 :  0.7800000000000006\n59000 :  0.7720000000000006\n59500 :  0.7240000000000005\n60000 :  0.7580000000000006\n60500 :  0.7740000000000006\n61000 :  0.7500000000000006\n61500 :  0.7440000000000005\n62000 :  0.7840000000000006\n62500 :  0.7580000000000006\n63000 :  0.7440000000000005\n63500 :  0.7860000000000006\n64000 :  0.7260000000000005\n64500 :  0.7520000000000006\n65000 :  0.7380000000000005\n65500 :  0.7460000000000006\n66000 :  0.7600000000000006\n66500 :  0.7520000000000006\n67000 :  0.7500000000000006\n67500 :  0.7880000000000006\n68000 :  0.7540000000000006\n68500 :  0.7160000000000005\n69000 :  0.7620000000000006\n69500 :  0.7560000000000006\n70000 :  0.7180000000000005\n70500 :  0.7740000000000006\n71000 :  0.7520000000000006\n71500 :  0.7860000000000006\n72000 :  0.7600000000000006\n72500 :  0.7440000000000005\n73000 :  0.7680000000000006\n73500 :  0.7740000000000006\n74000 :  0.7440000000000005\n74500 :  0.7340000000000005\n75000 :  0.7860000000000006\n75500 :  0.8180000000000006\n76000 :  0.7140000000000005\n76500 :  0.7340000000000005\n77000 :  0.7460000000000006\n77500 :  0.7840000000000006\n78000 :  0.7080000000000005\n78500 :  0.7920000000000006\n79000 :  0.7740000000000006\n79500 :  0.7820000000000006\n80000 :  0.7200000000000005\n80500 :  0.7060000000000005\n81000 :  0.7540000000000006\n81500 :  0.7580000000000006\n82000 :  0.7100000000000005\n82500 :  0.7500000000000006\n83000 :  0.7840000000000006\n83500 :  0.7640000000000006\n84000 :  0.7800000000000006\n84500 :  0.7340000000000005\n85000 :  0.7440000000000005\n85500 :  0.7540000000000006\n86000 :  0.7600000000000006\n86500 :  0.7620000000000006\n87000 :  0.7160000000000005\n87500 :  0.7620000000000006\n88000 :  0.7900000000000006\n88500 :  0.7280000000000005\n89000 :  0.7580000000000006\n89500 :  0.7420000000000005\n90000 :  0.7620000000000006\n90500 :  0.7700000000000006\n91000 :  0.7780000000000006\n91500 :  0.7720000000000006\n92000 :  0.7540000000000006\n92500 :  0.7560000000000006\n93000 :  0.7780000000000006\n93500 :  0.7600000000000006\n94000 :  0.7500000000000006\n94500 :  0.7340000000000005\n95000 :  0.7200000000000005\n95500 :  0.7640000000000006\n96000 :  0.8000000000000006\n96500 :  0.7380000000000005\n97000 :  0.7460000000000006\n97500 :  0.7820000000000006\n98000 :  0.7560000000000006\n98500 :  0.7560000000000006\n99000 :  0.7620000000000006\n99500 :  0.7540000000000006\n100000 :  0.7380000000000005\n","name":"stdout"}]},{"metadata":{"_uuid":"20495b6b-eea3-426f-a046-52c617597c31","_cell_guid":"03d64343-6efa-4130-ab19-9355e264fbf6","trusted":true},"cell_type":"code","source":"print(\"max:\", np.amax(accuracy), \"at:\", epochs/500 - (1+np.argmax(accuracy, axis=0)), \"to last row\")","execution_count":109,"outputs":[{"output_type":"stream","text":"max: 0.8180000000000006 at: 49.0 to last row\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Trials:\n* 0.806 & 0.802\n    * epochs = 50000\n    * max_steps = 200\n    * learning_rate = 0.09\n    * discount_rate = 0.99 \n    * exploration_rate = 1\n    * max_exploration_rate = 1\n    * min_exploration_rate = 0.01\n    * exploration_decay_rate = 0.001   \n* 0.782 & 0.784\n    * epochs = 10000(same as above but 1/5 the amount of epochs)\n    * max_steps = 200\n    * learning_rate = 0.09\n    * discount_rate = 0.99 \n    * exploration_rate = 1\n    * max_exploration_rate = 1\n    * min_exploration_rate = 0.01\n    * exploration_decay_rate = 0.001 \n* 0.818\n    * epochs = 100000(same as above but 1/5 the amount of epochs)\n    * max_steps = 300\n    * learning_rate = 0.09\n    * discount_rate = 0.99 \n    * exploration_rate = 1\n    * max_exploration_rate = 1\n    * min_exploration_rate = 0.01\n    * exploration_decay_rate = 0.001 \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(q_table)","execution_count":110,"outputs":[{"output_type":"stream","text":"[[0.5535096  0.52668216 0.51265377 0.50762933]\n [0.28948567 0.37899447 0.31819877 0.51529787]\n [0.43116976 0.43201604 0.42530365 0.47108634]\n [0.34345575 0.31659913 0.36544954 0.44183085]\n [0.56970152 0.45178143 0.44038537 0.39498596]\n [0.         0.         0.         0.        ]\n [0.34012094 0.15129203 0.13974951 0.13941627]\n [0.         0.         0.         0.        ]\n [0.22137729 0.39004322 0.33750436 0.59825085]\n [0.26988659 0.67030407 0.51635509 0.48457494]\n [0.59518243 0.42046194 0.35533805 0.22140881]\n [0.         0.         0.         0.        ]\n [0.         0.         0.         0.        ]\n [0.45462201 0.45246858 0.7733695  0.43959657]\n [0.70205455 0.91878884 0.76009179 0.74614123]\n [0.         0.         0.         0.        ]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Testing the model\n\n   -**to see the AI actually play, uncomment the print and time statements**"},{"metadata":{"trusted":true},"cell_type":"code","source":"win_loss = []\nfrom time import sleep\nfor episodes in range(1000):\n    state = env.reset()\n    done = False\n    #time.sleep(2)\n    while not done:\n        action = np.argmax(q_table[state,:])\n        new_state, reward, done, info = env.step(action)\n        #clear_output(wait = True)\n        #env.render()\n        #sleep(.3)\n        state = new_state\n    if reward == 1:\n        win_loss.append(\"Win\")\n        #print(\"******YOU WIN CONGRATZ!!!******\")\n        #time.sleep(1)\n    else:\n        win_loss.append(\"Loss\")\n        #print(\"******YOU LOSE******\")\n        #time.sleep(1)\n    #sleep(2)\n        ","execution_count":122,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = 0\nl = 0\nfor i in win_loss:\n    if i == \"Win\":\n        w+=1\n    else:\n        l+=1\nprint(\"Wins:\", w, \"Losses:\", l)","execution_count":120,"outputs":[{"output_type":"stream","text":"Wins: 1 Losses: 0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}